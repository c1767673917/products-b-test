#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é£ä¹¦å¤šç»´è¡¨æ ¼å›¾ç‰‡ä¸‹è½½å™¨
ç”¨äºä¸‹è½½è¡¨æ ¼ä¸­çš„å›¾ç‰‡æ–‡ä»¶
"""

import requests
import json
import os
import time
from urllib.parse import urlparse
from typing import List, Dict, Any, Optional
import pandas as pd
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

class FeishuImageDownloader:
    """é£ä¹¦å¤šç»´è¡¨æ ¼å›¾ç‰‡ä¸‹è½½å™¨"""
    
    def __init__(self, app_id: str, app_secret: str, max_workers: int = 2, rate_limit: float = 3.0):
        """åˆå§‹åŒ–ä¸‹è½½å™¨"""
        self.app_id = app_id
        self.app_secret = app_secret
        self.max_workers = max_workers  # é™ä½å¹¶å‘æ•°é¿å…APIé™åˆ¶
        self.rate_limit = rate_limit  # æ¯ç§’æœ€å¤§è¯·æ±‚æ•°
        self.min_interval = 1.0 / rate_limit  # æœ€å°è¯·æ±‚é—´éš”
        self.base_url = "https://open.feishu.cn"
        self.access_token = None
        self.token_expires_at = 0
        self.session = requests.Session()
        self.download_lock = threading.Lock()
        self.rate_limit_lock = threading.Lock()
        self.last_request_time = 0
        self.progress_count = 0
        self.retry_delay = 2  # é‡è¯•å»¶è¿Ÿ
        self.max_retries = 3  # æœ€å¤§é‡è¯•æ¬¡æ•°
        
    def get_tenant_access_token(self) -> Optional[str]:
        """è·å–ç§Ÿæˆ·è®¿é—®å‡­è¯"""
        if self.access_token and time.time() < self.token_expires_at:
            return self.access_token
            
        url = f"{self.base_url}/open-apis/auth/v3/tenant_access_token/internal"
        headers = {'Content-Type': 'application/json; charset=utf-8'}
        data = {"app_id": self.app_id, "app_secret": self.app_secret}
        
        try:
            response = self.session.post(url, headers=headers, json=data)
            response.raise_for_status()
            
            result = response.json()
            if result.get('code') == 0:
                self.access_token = result['tenant_access_token']
                self.token_expires_at = time.time() + result.get('expire', 7200) - 300
                return self.access_token
            else:
                print(f"âŒ è·å–è®¿é—®å‡­è¯å¤±è´¥: {result.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ è¯·æ±‚é”™è¯¯: {e}")
            return None

    def wait_for_rate_limit(self):
        """ç­‰å¾…ä»¥æ»¡è¶³é¢‘ç‡é™åˆ¶"""
        with self.rate_limit_lock:
            current_time = time.time()
            time_since_last = current_time - self.last_request_time

            if time_since_last < self.min_interval:
                sleep_time = self.min_interval - time_since_last
                print(f"â±ï¸  é¢‘ç‡é™åˆ¶ç­‰å¾… {sleep_time:.2f}s (æ¯ç§’æœ€å¤š{self.rate_limit}æ¬¡è¯·æ±‚)")
                time.sleep(sleep_time)

            self.last_request_time = time.time()

    def extract_image_info(self, records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ä»è®°å½•ä¸­æå–å›¾ç‰‡ä¿¡æ¯"""
        image_info_list = []
        
        # å®šä¹‰å›¾ç‰‡å­—æ®µ
        image_fields = ['æ­£é¢å›¾ç‰‡', 'èƒŒé¢å›¾ç‰‡', 'æ ‡ç­¾ç…§ç‰‡', 'å¤–åŒ…è£…å›¾ç‰‡', 'èµ å“å›¾ç‰‡']
        
        for record in records:
            record_id = record.get('record_id', '')
            fields = record.get('fields', {})
            
            # è·å–äº§å“åŸºæœ¬ä¿¡æ¯
            product_name = fields.get('å“å', 'æœªçŸ¥äº§å“')
            # ä½¿ç”¨ç¼–å·å­—æ®µä½œä¸ºæ–‡ä»¶å‘½ååŸºç¡€
            product_id = fields.get('ç¼–å·', 'æœªçŸ¥ç¼–å·')
            if not product_id or product_id == 'æœªçŸ¥ç¼–å·':
                # å¦‚æœç¼–å·å­—æ®µä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨åºå·å­—æ®µä½œä¸ºå¤‡ç”¨
                sequence_no = fields.get('åºå·', [{}])
                if isinstance(sequence_no, list) and len(sequence_no) > 0:
                    product_id = sequence_no[0].get('text', 'æœªçŸ¥ç¼–å·')
                else:
                    product_id = str(sequence_no) if sequence_no else 'æœªçŸ¥ç¼–å·'
            
            # éå†æ‰€æœ‰å›¾ç‰‡å­—æ®µ
            for field_name in image_fields:
                if field_name in fields and fields[field_name]:
                    images = fields[field_name]
                    if isinstance(images, list):
                        for i, image in enumerate(images):
                            if isinstance(image, dict):
                                image_info = {
                                    'record_id': record_id,
                                    'product_name': product_name,
                                    'product_id': product_id,  # ä½¿ç”¨ç¼–å·å­—æ®µ
                                    'field_name': field_name,
                                    'image_index': i,
                                    'file_token': image.get('file_token', ''),
                                    'file_name': image.get('name', ''),
                                    'file_size': image.get('size', 0),
                                    'file_type': image.get('type', ''),
                                    'download_url': image.get('url', ''),
                                    'tmp_url': image.get('tmp_url', '')
                                }
                                image_info_list.append(image_info)
        
        print(f"ğŸ“¸ æ‰¾åˆ° {len(image_info_list)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
        return image_info_list
    
    def get_real_download_url(self, file_token: str, tmp_url: str) -> Optional[str]:
        """è·å–çœŸå®çš„ä¸‹è½½é“¾æ¥"""
        access_token = self.get_tenant_access_token()
        if not access_token:
            return None

        headers = {'Authorization': f'Bearer {access_token}'}

        try:
            # ä½¿ç”¨æ‰¹é‡è·å–ä¸´æ—¶ä¸‹è½½é“¾æ¥çš„API
            api_url = f"{self.base_url}/open-apis/drive/v1/medias/batch_get_tmp_download_url"
            params = {
                'file_tokens': file_token,
                'extra': f'{{"bitablePerm":{{"tableId":"tblwdwrZMikMRyxq","rev":2778}}}}'
            }

            print(f"ğŸ”— è·å–ä¸‹è½½é“¾æ¥: {api_url}")
            response = self.session.get(api_url, headers=headers, params=params)
            response.raise_for_status()

            result = response.json()
            if result.get('code') == 0:
                tmp_download_urls = result.get('data', {}).get('tmp_download_urls', [])
                if tmp_download_urls and len(tmp_download_urls) > 0:
                    real_url = tmp_download_urls[0].get('tmp_download_url', '')
                    if real_url:
                        print(f"âœ… è·å–åˆ°çœŸå®ä¸‹è½½é“¾æ¥: {real_url[:100]}...")
                        return real_url

            print(f"âŒ è·å–ä¸‹è½½é“¾æ¥å¤±è´¥: {result}")
            return None

        except Exception as e:
            print(f"âŒ è·å–ä¸‹è½½é“¾æ¥å¼‚å¸¸: {e}")
            return None

    def download_image(self, image_info: Dict[str, Any], output_dir: str) -> bool:
        """ä¸‹è½½å•ä¸ªå›¾ç‰‡"""
        # åº”ç”¨é¢‘ç‡é™åˆ¶
        self.wait_for_rate_limit()

        access_token = self.get_tenant_access_token()
        if not access_token:
            return False

        # è·å–çœŸå®çš„ä¸‹è½½é“¾æ¥
        file_token = image_info.get('file_token', '')
        tmp_url = image_info.get('tmp_url', '')

        if not file_token:
            print(f"âŒ å›¾ç‰‡ {image_info['file_name']} ç¼ºå°‘ file_token")
            return False

        # è·å–çœŸå®ä¸‹è½½é“¾æ¥
        real_download_url = self.get_real_download_url(file_token, tmp_url)
        if not real_download_url:
            print(f"âŒ æ— æ³•è·å–å›¾ç‰‡ {image_info['file_name']} çš„ä¸‹è½½é“¾æ¥")
            return False

        # ä¸éœ€è¦Authorizationå¤´ï¼Œå› ä¸ºçœŸå®ä¸‹è½½é“¾æ¥å·²ç»åŒ…å«äº†è®¤è¯ä¿¡æ¯
        headers = {}

        try:
            # å‘èµ·ä¸‹è½½è¯·æ±‚
            print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½: {image_info['file_name']}")
            response = self.session.get(real_download_url, headers=headers, stream=True)
            response.raise_for_status()

            # æ„å»ºæ–‡ä»¶å
            product_id = image_info['product_id'].replace('/', '_')  # ä½¿ç”¨ç¼–å·å­—æ®µ
            field_name = image_info['field_name']
            original_name = image_info['file_name']

            # è·å–æ–‡ä»¶æ‰©å±•å
            if original_name:
                _, ext = os.path.splitext(original_name)
            else:
                ext = '.jpg'  # é»˜è®¤æ‰©å±•å

            # æ„å»ºå®Œæ•´æ–‡ä»¶å - ä½¿ç”¨ç¼–å·å­—æ®µä½œä¸ºæ–‡ä»¶åå‰ç¼€
            safe_filename = f"{product_id}_{field_name}_{image_info['image_index']}{ext}"
            file_path = os.path.join(output_dir, safe_filename)

            # ä¿å­˜æ–‡ä»¶
            with open(file_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)

            file_size = os.path.getsize(file_path)
            print(f"âœ… ä¸‹è½½æˆåŠŸ: {safe_filename} ({file_size} bytes)")

            # æ›´æ–°å›¾ç‰‡ä¿¡æ¯
            image_info['local_path'] = file_path
            image_info['download_success'] = True

            return True

        except requests.exceptions.RequestException as e:
            # è·å–æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
            error_detail = str(e)
            if hasattr(e, 'response') and e.response is not None:
                try:
                    error_json = e.response.json()
                    error_detail = f"{e} - å“åº”: {error_json}"
                except:
                    error_detail = f"{e} - çŠ¶æ€ç : {e.response.status_code}"

            print(f"âŒ ä¸‹è½½å¤±è´¥ {image_info['file_name']}: {error_detail}")
            image_info['download_success'] = False
            image_info['error_message'] = error_detail
            return False
        except Exception as e:
            print(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ {image_info['file_name']}: {e}")
            image_info['download_success'] = False
            image_info['error_message'] = str(e)
            return False
    
    def download_single_image_thread(self, image_info: Dict[str, Any], output_dir: str, total_count: int) -> bool:
        """å•ä¸ªå›¾ç‰‡ä¸‹è½½çš„çº¿ç¨‹å‡½æ•°"""
        # é¢‘ç‡é™åˆ¶å·²åœ¨ download_image æ–¹æ³•ä¸­å®ç°
        success = self.download_image(image_info, output_dir)

        with self.download_lock:
            self.progress_count += 1
            print(f"ğŸ“¥ ä¸‹è½½è¿›åº¦: {self.progress_count}/{total_count} - {image_info['file_name']} {'âœ…' if success else 'âŒ'}")

        return success

    def download_all_images(self, records: List[Dict[str, Any]], output_base_dir: str, create_timestamp_dir: bool = False) -> Dict[str, Any]:
        """ä¸‹è½½æ‰€æœ‰å›¾ç‰‡ï¼ˆå¤šçº¿ç¨‹ç‰ˆæœ¬ï¼‰"""
        # æå–å›¾ç‰‡ä¿¡æ¯
        image_info_list = self.extract_image_info(records)

        if not image_info_list:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
            return {'success': 0, 'failed': 0, 'total': 0}

        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦åˆ›å»ºæ—¶é—´æˆ³å­ç›®å½•
        if create_timestamp_dir:
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            output_dir = os.path.join(output_base_dir, f"images_{timestamp}")
        else:
            output_dir = output_base_dir
        os.makedirs(output_dir, exist_ok=True)

        print(f"ğŸ“ å›¾ç‰‡å°†ä¿å­˜åˆ°: {output_dir}")
        print(f"ğŸš€ ä½¿ç”¨ {self.max_workers} ä¸ªçº¿ç¨‹å¹¶è¡Œä¸‹è½½ï¼Œé¢‘ç‡é™åˆ¶: æ¯ç§’æœ€å¤š{self.rate_limit}æ¬¡è¯·æ±‚...")

        # é‡ç½®è¿›åº¦è®¡æ•°å™¨
        self.progress_count = 0

        # ä½¿ç”¨çº¿ç¨‹æ± ä¸‹è½½å›¾ç‰‡
        success_count = 0
        failed_count = 0

        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            # æäº¤æ‰€æœ‰ä¸‹è½½ä»»åŠ¡
            future_to_image = {
                executor.submit(self.download_single_image_thread, image_info, output_dir, len(image_info_list)): image_info
                for image_info in image_info_list
            }

            # æ”¶é›†ç»“æœ
            for future in as_completed(future_to_image):
                if future.result():
                    success_count += 1
                else:
                    failed_count += 1
        
        # ç”Ÿæˆä¸‹è½½æŠ¥å‘Š
        report = {
            'total': len(image_info_list),
            'success': success_count,
            'failed': failed_count,
            'output_dir': output_dir,
            'image_info_list': image_info_list
        }
        
        # ä¿å­˜å›¾ç‰‡ä¿¡æ¯åˆ°CSV
        df = pd.DataFrame(image_info_list)
        csv_path = os.path.join(output_dir, 'image_download_report.csv')
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆä¸‹è½½æŠ¥å‘Š
        self.generate_download_report(report, output_dir)
        
        print(f"\nğŸ“Š ä¸‹è½½å®Œæˆç»Ÿè®¡:")
        print(f"   æ€»è®¡: {report['total']} ä¸ªæ–‡ä»¶")
        print(f"   æˆåŠŸ: {report['success']} ä¸ªæ–‡ä»¶")
        print(f"   å¤±è´¥: {report['failed']} ä¸ªæ–‡ä»¶")
        print(f"   æˆåŠŸç‡: {(success_count/len(image_info_list)*100):.1f}%")
        
        return report
    
    def generate_download_report(self, report: Dict[str, Any], output_dir: str):
        """ç”Ÿæˆä¸‹è½½æŠ¥å‘Š"""
        report_path = os.path.join(output_dir, 'download_report.txt')
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("é£ä¹¦å¤šç»´è¡¨æ ¼å›¾ç‰‡ä¸‹è½½æŠ¥å‘Š\n")
            f.write("=" * 50 + "\n\n")
            
            f.write(f"ğŸ“Š ä¸‹è½½ç»Ÿè®¡\n")
            f.write(f"æ€»æ–‡ä»¶æ•°: {report['total']}\n")
            f.write(f"æˆåŠŸä¸‹è½½: {report['success']}\n")
            f.write(f"ä¸‹è½½å¤±è´¥: {report['failed']}\n")
            f.write(f"æˆåŠŸç‡: {(report['success']/report['total']*100):.1f}%\n\n")
            
            # æŒ‰å­—æ®µç±»å‹ç»Ÿè®¡
            f.write(f"ğŸ“¸ æŒ‰å›¾ç‰‡ç±»å‹ç»Ÿè®¡\n")
            field_stats = {}
            for img in report['image_info_list']:
                field_name = img['field_name']
                if field_name not in field_stats:
                    field_stats[field_name] = {'total': 0, 'success': 0}
                field_stats[field_name]['total'] += 1
                if img.get('download_success', False):
                    field_stats[field_name]['success'] += 1
            
            for field_name, stats in field_stats.items():
                success_rate = (stats['success'] / stats['total'] * 100) if stats['total'] > 0 else 0
                f.write(f"{field_name}: {stats['success']}/{stats['total']} ({success_rate:.1f}%)\n")
            
            f.write(f"\nğŸ“ æ–‡ä»¶ä¿å­˜ä½ç½®\n")
            f.write(f"ç›®å½•: {output_dir}\n")
            
            # å¤±è´¥æ–‡ä»¶åˆ—è¡¨
            failed_files = [img for img in report['image_info_list'] if not img.get('download_success', False)]
            if failed_files:
                f.write(f"\nâŒ ä¸‹è½½å¤±è´¥çš„æ–‡ä»¶\n")
                for img in failed_files:
                    f.write(f"- {img['file_name']} ({img.get('error_message', 'æœªçŸ¥é”™è¯¯')})\n")


def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®ä¿¡æ¯
    APP_ID = "cli_a8e575c35763d013"
    APP_SECRET = "41VyUJHWqFBoiOr5dOwgqctKwSn1RqWf"
    
    print("ğŸ–¼ï¸ å¼€å§‹ä¸‹è½½é£ä¹¦å¤šç»´è¡¨æ ¼ä¸­çš„å›¾ç‰‡...")
    print("=" * 60)
    
    # æŸ¥æ‰¾æœ€æ–°çš„æ•°æ®æ–‡ä»¶
    data_dirs = [d for d in os.listdir('.') if d.startswith('feishu_data_') and os.path.isdir(d)]
    if not data_dirs:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®ç›®å½•ï¼Œè¯·å…ˆè¿è¡Œ feishu_data_analyzer.py")
        return
    
    latest_dir = sorted(data_dirs)[-1]
    json_path = os.path.join(latest_dir, 'raw_data.json')
    
    if not os.path.exists(json_path):
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {json_path}")
        return
    
    print(f"ğŸ“‚ ä½¿ç”¨æ•°æ®æ–‡ä»¶: {json_path}")
    
    # åŠ è½½æ•°æ®
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            records = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(records)} æ¡è®°å½•")
    except Exception as e:
        print(f"âŒ åŠ è½½æ•°æ®å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºä¸‹è½½å™¨ï¼ˆä½¿ç”¨3ä¸ªçº¿ç¨‹ï¼Œé¢‘ç‡é™åˆ¶ä¸ºæ¯ç§’3æ¬¡ï¼‰
    downloader = FeishuImageDownloader(APP_ID, APP_SECRET, max_workers=3, rate_limit=3.0)
    
    # è®¾ç½®è¾“å‡ºç›®å½•ä¸ºproduct-showcase/public/images
    output_dir = "product-showcase/public/images"
    os.makedirs(output_dir, exist_ok=True)

    # ä¸‹è½½å›¾ç‰‡
    report = downloader.download_all_images(records, output_dir)
    
    print("\nâœ¨ å›¾ç‰‡ä¸‹è½½å®Œæˆ!")


def download_missing_images():
    """è¡¥å……ä¸‹è½½ç¼ºå¤±çš„å›¾ç‰‡"""
    # é…ç½®ä¿¡æ¯
    APP_ID = "cli_a8fa1d87c3fad00d"
    APP_SECRET = "CDfRPlOw8VRQrPyLnpzNvd5wBmu6wROp"

    print("ğŸ”„ å¼€å§‹è¡¥å……ä¸‹è½½ç¼ºå¤±çš„å›¾ç‰‡...")
    print("=" * 60)

    # è¯»å–ç¼ºå¤±å›¾ç‰‡åˆ—è¡¨
    missing_csv_path = "product-showcase/src/data/missing_images.csv"
    if not os.path.exists(missing_csv_path):
        print(f"âŒ æœªæ‰¾åˆ°ç¼ºå¤±å›¾ç‰‡åˆ—è¡¨: {missing_csv_path}")
        print("è¯·å…ˆè¿è¡Œå›¾ç‰‡çŠ¶æ€åˆ†æè„šæœ¬")
        return

    # è¯»å–ç¼ºå¤±å›¾ç‰‡æ•°æ®
    try:
        missing_df = pd.read_csv(missing_csv_path)
        print(f"ğŸ“‹ å‘ç° {len(missing_df)} ä¸ªç¼ºå¤±çš„å›¾ç‰‡")
    except Exception as e:
        print(f"âŒ è¯»å–ç¼ºå¤±å›¾ç‰‡åˆ—è¡¨å¤±è´¥: {e}")
        return

    # æŸ¥æ‰¾æœ€æ–°çš„åŸå§‹æ•°æ®æ–‡ä»¶
    data_dirs = [d for d in os.listdir('.') if d.startswith('feishu_data_') and os.path.isdir(d)]
    if not data_dirs:
        print("âŒ æœªæ‰¾åˆ°æ•°æ®ç›®å½•ï¼Œè¯·å…ˆè¿è¡Œ feishu_data_analyzer.py")
        return

    latest_dir = sorted(data_dirs)[-1]
    json_path = os.path.join(latest_dir, 'raw_data.json')

    if not os.path.exists(json_path):
        print(f"âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶: {json_path}")
        return

    # åŠ è½½åŸå§‹æ•°æ®
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            all_records = json.load(f)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(all_records)} æ¡åŸå§‹è®°å½•")
    except Exception as e:
        print(f"âŒ åŠ è½½åŸå§‹æ•°æ®å¤±è´¥: {e}")
        return

    # åˆ›å»ºäº§å“IDåˆ°è®°å½•çš„æ˜ å°„
    product_id_to_record = {}
    for record in all_records:
        fields = record.get('fields', {})
        product_id = fields.get('ç¼–å·')
        if product_id:
            product_id_to_record[product_id] = record

    # ç­›é€‰éœ€è¦ä¸‹è½½çš„è®°å½•
    records_to_download = []
    missing_product_ids = set(missing_df['ProductID'].unique())

    for product_id in missing_product_ids:
        if product_id in product_id_to_record:
            records_to_download.append(product_id_to_record[product_id])

    print(f"ğŸ¯ æ‰¾åˆ° {len(records_to_download)} ä¸ªäº§å“éœ€è¦è¡¥å……ä¸‹è½½å›¾ç‰‡")

    if not records_to_download:
        print("âœ… æ²¡æœ‰éœ€è¦è¡¥å……ä¸‹è½½çš„å›¾ç‰‡")
        return

    # åˆ›å»ºä¸‹è½½å™¨ï¼ˆä½¿ç”¨ä¿å®ˆçš„è®¾ç½®ï¼š1ä¸ªçº¿ç¨‹ï¼Œé¢‘ç‡é™åˆ¶ä¸ºæ¯ç§’3æ¬¡ï¼‰
    downloader = FeishuImageDownloader(APP_ID, APP_SECRET, max_workers=1, rate_limit=3.0)

    # è®¾ç½®è¾“å‡ºç›®å½•
    output_dir = "product-showcase/public/images"
    os.makedirs(output_dir, exist_ok=True)

    # ä¸‹è½½å›¾ç‰‡
    print(f"ğŸš€ å¼€å§‹ä¸‹è½½ï¼Œä½¿ç”¨1ä¸ªçº¿ç¨‹ï¼Œé¢‘ç‡é™åˆ¶æ¯ç§’3æ¬¡...")
    report = downloader.download_all_images(records_to_download, output_dir)

    print("\nâœ¨ ç¼ºå¤±å›¾ç‰‡è¡¥å……ä¸‹è½½å®Œæˆ!")
    return report


if __name__ == "__main__":
    import sys
    if len(sys.argv) > 1 and sys.argv[1] == "missing":
        download_missing_images()
    else:
        main()
